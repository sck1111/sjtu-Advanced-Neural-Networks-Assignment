{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLFRgjnrkRlC",
        "outputId": "644644b8-893f-4b4d-869b-6ac0f3fe3ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43098489.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "def load_cifar10(batch_size=64, img_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(img_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    return trainloader\n",
        "\n",
        "# Load CIFAR-10 dataset with drop_last=True\n",
        "dataloader = load_cifar10()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf data"
      ],
      "metadata": {
        "id": "BBHwy8DT47cf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "class DCGAN_Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, img_shape):\n",
        "        super(DCGAN_Generator, self).__init__()\n",
        "        self.img_shape = img_shape\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.BatchNorm1d(256, 0.8),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512, 0.8),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, int(np.prod(img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), *self.img_shape)\n",
        "        return img\n",
        "\n",
        "class DCGAN_Discriminator(nn.Module):\n",
        "    def __init__(self, img_shape):\n",
        "        super(DCGAN_Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(img_shape)), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity\n",
        "\n",
        "latent_dim = 100\n",
        "img_shape = (3, 32, 32)\n",
        "dcgan_generator = DCGAN_Generator(latent_dim, img_shape)\n",
        "dcgan_discriminator = DCGAN_Discriminator(img_shape)\n",
        "\n",
        "optimizer_G = torch.optim.Adam(dcgan_generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(dcgan_discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "criterion = torch.nn.BCELoss()\n"
      ],
      "metadata": {
        "id": "QOBpBu41kWbi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import save_image\n",
        "import time\n",
        "training_times = []\n",
        "\n",
        "def train_dcgan(generator, discriminator, optimizer_G, optimizer_D, dataloader, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        for i, (imgs, _) in enumerate(dataloader):\n",
        "            real_imgs = imgs.cuda()\n",
        "            valid = torch.ones(imgs.size(0), 1).cuda()\n",
        "            fake = torch.zeros(imgs.size(0), 1).cuda()\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "            noise = torch.randn(imgs.size(0), 100).cuda()\n",
        "            gen_imgs = generator(noise)\n",
        "\n",
        "            # Debug: Print batch sizes\n",
        "            # print(f'Real images batch size: {real_imgs.size(0)}')\n",
        "            # print(f'Generated images batch size: {gen_imgs.size(0)}')\n",
        "\n",
        "            g_loss = criterion(discriminator(gen_imgs), valid)\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            optimizer_D.zero_grad()\n",
        "            real_loss = criterion(discriminator(real_imgs), valid)\n",
        "            fake_loss = criterion(discriminator(gen_imgs.detach()), fake)\n",
        "            d_loss = (real_loss + fake_loss) / 2\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_time = end_time - start_time\n",
        "        training_times.append(epoch_time)\n",
        "\n",
        "    return gen_imgs\n",
        "\n",
        "total_training_time = sum(training_times)\n",
        "avg_training_time_per_epoch = total_training_time / num_epochs\n",
        "\n",
        "print(f\"Total training time: {total_training_time} seconds\")\n",
        "print(f\"Avg training time per epoch: {avg_training_time_per_epoch} seconds\")\n",
        "\n",
        "dcgan_generator.cuda()\n",
        "dcgan_discriminator.cuda()\n",
        "gen_imgs_dcgan = train_dcgan(dcgan_generator, dcgan_discriminator, optimizer_G, optimizer_D, dataloader, epochs=50)\n",
        "save_image(gen_imgs_dcgan.data[:25], 'dcgan_generated.png', nrow=5, normalize=True)"
      ],
      "metadata": {
        "id": "mp9e3iWikZPB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Summarize and visualize results\n",
        "def summarize_results(fid_scores, psnr_scores, ssim_scores, training_times):\n",
        "    results = {\n",
        "        'Model': ['DCGAN', 'VAE', 'WGAN-GP'],\n",
        "        'FID Score': fid_scores,\n",
        "        'PSNR': psnr_scores,\n",
        "        'SSIM': ssim_scores,\n",
        "        'Training Time (s)': training_times\n",
        "    }\n",
        "\n",
        "    df_results = pd.DataFrame(results)\n",
        "    print(df_results)\n",
        "\n",
        "    df_results.plot(x='Model', y=['FID Score', 'PSNR', 'SSIM', 'Training Time (s)'], kind='bar', subplots=True, layout=(2, 2), figsize=(14, 10))\n",
        "    plt.show()\n",
        "\n",
        "# Collect scores\n",
        "fid_scores = [fid_dcgan, fid_vae, fid_wgan_gp]\n",
        "psnr_scores = [psnr_dcgan, psnr_vae, psnr_wgan_gp]\n",
        "ssim_scores = [ssim_dcgan, ssim_vae, ssim_wgan_gp]\n",
        "# Assume training times are recorded\n",
        "training_times = [1000, 1200, 1100]\n",
        "\n",
        "summarize_results(fid_scores, psnr_scores, ssim_scores, training_times)\n"
      ],
      "metadata": {
        "id": "r6WJEWjg92Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(real_imgs), len(gen_imgs_dcgan))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHq8dU3szbsY",
        "outputId": "97fa15cb-e252-403a-c05d-3f25b30cc144"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-SqcyFRO7Rb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gXdeQrZL7RfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FID Score (Fréchet Inception Distance):\n",
        "\n",
        "含义：FID Score 是一种衡量生成图像质量的指标，通过比较真实图像与生成图像在特征空间上的统计分布差异来评估。它利用了预训练的深度学习模型（通常是 Inception 网络）提取的特征向量，计算两个分布之间的 Fréchet 距离。\n",
        "解释：FID Score 越低表示生成图像与真实图像的统计分布越接近，生成器的质量越高。\n",
        "\n",
        "PSNR (Peak Signal-to-Noise Ratio):\n",
        "\n",
        "含义：PSNR 是一种用于测量图像质量的传统指标，它评估了生成图像与真实图像之间的峰值信噪比。PSNR 越高表示两幅图像之间的结构相似度越高。\n",
        "解释：PSNR 是在像素级别计算的，较高的 PSNR 值意味着生成图像的像素值与真实图像的像素值非常接近，即图像质量较高。\n",
        "\n",
        "SSIM (Structural Similarity Index):\n",
        "\n",
        "含义：SSIM 是另一种用于测量图像相似性的指标，它不仅考虑像素级别的差异，还考虑亮度、对比度和结构信息之间的相关性。\n",
        "解释：SSIM 的值在 0 到 1 之间，越接近 1 表示生成图像与真实图像在结构上越相似，即生成图像的结构与真实图像更接近。\n",
        "\n",
        "总结：\n",
        "FID Score 衡量生成图像与真实图像在特征空间上的分布相似性。\n",
        "\n",
        "PSNR 衡量生成图像与真实图像之间的像素级别相似性。\n",
        "\n",
        "SSIM 衡量生成图像与真实图像之间的结构相似性。"
      ],
      "metadata": {
        "id": "mRyocKXG6oUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import sqrtm\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
        "\n",
        "def calculate_fid(real_images, generated_images):\n",
        "    mu_real, sigma_real = np.mean(real_images, axis=0), np.cov(real_images, rowvar=False)\n",
        "    mu_gen, sigma_gen = np.mean(generated_images, axis=0), np.cov(generated_images, rowvar=False)\n",
        "    ssdiff = np.sum((mu_real - mu_gen)**2.0)\n",
        "    covmean = sqrtm(sigma_real.dot(sigma_gen))\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "    fid = ssdiff + np.trace(sigma_real + sigma_gen - 2.0 * covmean)\n",
        "    return fid\n",
        "\n",
        "def calculate_psnr(real_images, generated_images):\n",
        "    assert len(real_images) == len(generated_images), \"Length of real_images and generated_images must be the same\"\n",
        "\n",
        "    psnr_values = [\n",
        "        psnr(real_images[i].detach().cpu().numpy().transpose(1, 2, 0),\n",
        "             generated_images[i].detach().cpu().numpy().transpose(1, 2, 0))\n",
        "        for i in range(len(real_images))\n",
        "    ]\n",
        "    return np.mean(psnr_values)\n",
        "\n",
        "def calculate_ssim(real_images, generated_images):\n",
        "    ssim_values = [ssim(real_images[i].detach().cpu().numpy().transpose(1, 2, 0),\n",
        "            generated_images[i].detach().cpu().numpy().transpose(1, 2, 0), multichannel=True) for i in range(len(real_images))]\n",
        "    return np.mean(ssim_values)\n",
        "\n",
        "# Prepare data for FID calculation\n",
        "real_imgs, _ = next(iter(dataloader))\n",
        "real_imgs_flat = real_imgs.view(real_imgs.size(0), -1).detach().numpy()\n",
        "gen_imgs_dcgan_flat = gen_imgs_dcgan.view(gen_imgs_dcgan.size(0), -1).detach().cpu().numpy()\n",
        "# gen_imgs_vae_flat = gen_imgs_vae.view(gen_imgs_vae.size(0), -1).detach().cpu().numpy()\n",
        "# gen_imgs_wgan_gp_flat = gen_imgs_wgan_gp.view(gen_imgs_wgan_gp.size(0), -1).detach().cpu().numpy()\n",
        "\n",
        "# Calculate FID\n",
        "fid_dcgan = calculate_fid(real_imgs_flat, gen_imgs_dcgan_flat)\n",
        "# fid_vae = calculate_fid(real_imgs_flat, gen_imgs_vae_flat)\n",
        "# fid_wgan_gp = calculate_fid(real_imgs_flat, gen_imgs_wgan_gp_flat)\n",
        "\n",
        "# Calculate PSNR and SSIM\n",
        "psnr_dcgan = calculate_psnr(real_imgs, gen_imgs_dcgan)\n",
        "ssim_dcgan = calculate_ssim(real_imgs, gen_imgs_dcgan)\n",
        "# psnr_vae = calculate_psnr(real_imgs, gen_imgs_vae)\n",
        "# ssim_vae = calculate_ssim(real_imgs, gen_imgs_vae)\n",
        "# psnr_wgan_gp = calculate_psnr(real_imgs, gen_imgs_wgan_gp)\n",
        "# ssim_wgan_gp = calculate_ssim(real_imgs, gen_imgs_wgan_gp)\n",
        "\n",
        "# Print metrics\n",
        "print(f'FID Score for DCGAN: {fid_dcgan}')\n",
        "print(f'PSNR for DCGAN: {psnr_dcgan}')\n",
        "print(f'SSIM for DCGAN: {ssim_dcgan}')\n",
        "# print(f'FID Score for VAE: {fid_vae}')\n",
        "# print(f'PSNR for VAE: {psnr_vae}')\n",
        "# print(f'SSIM for VAE: {ssim_vae}')\n",
        "# print(f'FID Score for WGAN-GP: {fid_wgan_gp}')\n",
        "# print(f'PSNR for WGAN-GP: {psnr_wgan_gp}')\n",
        "# print(f'SSIM for WGAN-GP: {ssim_wgan_gp}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E5uMn7ykd73",
        "outputId": "3e49bd0c-e34f-492c-aecc-883400eb1951"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID Score for DCGAN: 4.92525077454931e+114\n",
            "PSNR for DCGAN: 9.971077916296816\n",
            "SSIM for DCGAN: 0.009066807106137276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-4121c343cf64>:26: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  ssim_values = [ssim(real_images[i].detach().cpu().numpy().transpose(1, 2, 0),\n"
          ]
        }
      ]
    }
  ]
}